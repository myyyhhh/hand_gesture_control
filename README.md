## 1.  引言

本实验报告是为完成 pythno 课程作业项目所写。

本项目主要是开发一款**通过手势简单控制电脑**的应用程序——**手势控制系统**。

本项目基于 python、mediapipe 完成。

## 2. 项目功能

本手势控制系统是一款基于计算机视觉技术的无接触交互工具，支持**通过手部姿态与动作控制电脑核心操作**，具备直观、精准、可自定义的交互体验，核心功能分为以下模块：

#### 2.1 手部检测与关键点追踪

- **视频采集**：调用摄像头读取画面，限制仅追踪单只手部，保证识别效率。
- **稳定追踪**：设置了较高的检测置信度（0.7）和追踪置信度（0.5），即使在手部快速移动或旋转时，也能保持关键点不丢失。
- **可视化调试**：在画面上实时绘制 21 个手部骨骼关键点，并显示当前的 FPS 和识别到的手势名称，方便直观判断系统是否正常运行。

#### 2.2 鼠标控制功能

- **光标移动**：采用**小指伸直即激活**的逻辑（以食指根部为锚点），配合平滑滤波算法，有效消除手部生理抖动带来的光标晃动。
- **拖拽与点击**：
  - *拖拽*：食指+小指同时伸直，模拟按住鼠标左键不放。
  - *点击*：小指弯曲时，食指单独伸直触发左键，中指单独伸直触发右键，逻辑判定清晰，防误触效果好。
- **非线性加速**：内置了一套鼠标加速算法，慢速移动时保证像素级精度，快速挥手时能跨越屏幕长距离，解决了“手伸太远够不到屏幕边缘”的问题。

#### 2.3 滚动控制功能（虚拟摇杆）

- **原点锁定**：当检测到*仅拇指伸直*时，系统会锁定当前手掌位置作为“虚拟摇杆”的原点。
- **双轴滚动**：
  - 手掌相对于原点上下偏移 -> 触发垂直滚动（浏览网页）。
  - 手掌相对于原点左右偏移 -> 触发水平滚动。
- **防抖死区**：在原点周围设置了 5% 的死区范围，微小的手部晃动不会触发滚动，只有明显的偏移才会响应。

#### 2.4. 音量控制功能

- **模式激活**：*五指全开时进入音量控制模式*，以激活瞬间的手掌中心为原点，支持垂直方向音量调节与水平方向静音切换。
- **音量调节**：*手掌向上移动增加音量、向下移动降低音量*，调节步长可自定义，避免音量突变。
- **静音切换**：*手掌大幅向左移动（超过阈值 0.15）时触发静音 / 取消静音切换*，设置触发锁定机制，防止重复切换。

#### 2.5. 可视化 GUI 与参数配置

- **界面设计**：使用 PyQt5 开发了控制面板，左侧显示实时画面，右侧提供参数调节。
- **热更新参数**：鼠标灵敏度、平滑系数、滚动速度等参数支持**拖动滑块即时生效**，无需重启程序，方便调试出最佳手感。
- **状态监视**：底部状态栏实时显示分辨率、帧率和运行日志，遇到摄像头被占用等错误时会自动弹窗提示并安全停止线程。

#### 2.6. 辅助功能

- **兼容性**：自适应不同分辨率的摄像头（默认 640x480），支持主流 Windows 环境。
- **防误触机制**：在代码层面做了多重校验（如关键点坐标的相对位置、动作幅度限制），最大程度减少背景干扰导致的误操作。

## 3.  实现思路

- 感知层：封装 `Camera` 类与 `HandDetector` 类，负责图像采集与 MediaPipe 推理，输出标准化的关键点坐标（Landmarks）。

- 识别层：`GestureRecognizer` 通过几何解析（如指尖与关节的向量关系、拇指外展距离）将坐标数据抽象为语义化的 `GestureType` 枚举（如 `Pointing`, `Scroll`）。

- 控制层：`ActionMapper` 充当状态机，维护当前交互状态（如是否按住左键、原点位置），并将手势指令映射为 `pyautogui` 的系统级操作。

- 交互层：主线程运行 PyQt5 事件循环，子线程（WorkerThread）运行上述核心逻辑，通过 PyQt 信号槽机制（Signal-Slot）实现视频流与状态数据的跨线程同步。

#### 3.1 整体架构

- **感知层**：负责“看”，从摄像头获取图片并提取坐标。
- **识别层**：负责“想”，分析坐标算出手指是弯是直，判断当前是什么手势。
- **控制层**：负责“做”，把手势转换成具体的鼠标点击或键盘指令。
- **交互层**：负责“展示”，提供图形界面给用户操作。

#### 3.2 感知层

- **图像采集**：使用 OpenCV (cv2) 读取视频流，统一缩放到 640x480 以保证处理速度。
- **关键点提取**：调用 MediaPipe Hands 模型。这里做了一个优化：并没有每帧都重新检测手掌，而是利用 MediaPipe 的追踪机制，只在置信度低时才重新运行检测模型，从而稳定在 30FPS 以上。
- **坐标归一化**：将检测到的坐标通过 landmark_utils 转换为便于计算的相对坐标。

#### 3.3 识别层

- **手指状态解算**：
  - *大拇指*：判断指尖是否比指关节更远离手掌中心（X轴方向）。
  - *其他四指*：简单判断指尖的 Y 坐标是否高于指关节（屏幕坐标系 Y 轴向下）。
- **规则分类**：没有使用复杂的深度学习分类网络，而是采用**几何规则树**。例如：if 拇指伸直 and 其他弯曲 -> return SCROLL_MODE。这种方法计算量极小，且对于定义好的几种手势非常准确。

#### 3.4 控制层

- **映射与平滑**：
  - 使用 pyautogui 库来模拟键鼠操作。
  - 为了解决手抖问题，引入了**滑动平均算法（Smoother）**，当前的鼠标位置由“上一帧位置”和“当前检测位置”加权计算得出，权重系数可在 GUI 中调节。
- **虚拟摇杆逻辑**：
  - 在进入滚动/音量模式的第一帧记录 origin_pos。
  - 后续每一帧计算 current_pos - origin_pos，只有差值超过 deadzone 才触发操作，实现了类似游戏手柄摇杆的操控感。

#### 3.5 交互层

- **多线程防卡死**：主要逻辑运行在 QThread 子线程中，复杂的图像处理不会阻塞 PyQt 的主界面刷新。
- **参数同步**：利用 PyQt 的信号机制，当用户拖动 GUI 上的滑块时，直接更新 Settings 全局配置，子线程下一帧处理时就能读取到最新参数。

## 4. 技术栈

- **Python**       3.11.5：编程语言
- **mediapipe**     0.10.21：用于手部识别功能开发
- **PyQt5**       5.15.11：用于构建图形用户界面
- **opencv-python**   4.8.0.76：用于视频采集、图像处理
- **PyAutoGUI**     0.9.54：用于模拟鼠标移动、点击、拖拽、滚动等电脑操作
- **Windows API**：通过系统接口实现音量调节与静音功能

## 5. 开发环境（Development Environment）

- **软件环境**
  - Windows 11 家庭中文版 24H2；
  - Python 3.11.5
  - mediapipe 0.10.21

- **硬件环境**
  - CPU：AMD Ryzen 7840H
  - 摄像头：Integrated Camera by Realtek

- **开发工具**
  - Visual Studio Code

## 6. 用户交互（User Interaction）


用户启动程序后，会得到以上界面，界面有：

- **启动系统**、**停止系统**按钮：用于启动、停止系统
- **参数调节**：这里可以调节部分系统参数

- **系统状态**：这里给出部分系统状态信息
- **手势操作说明**

